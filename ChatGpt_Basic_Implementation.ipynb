{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCJdAN9Misq1jcTuiDTNH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunmalik11/Task-199-Basic-OpenAi-Implementation/blob/main/ChatGpt_Basic_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies"
      ],
      "metadata": {
        "id": "8bIbLX3V6yrK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTerhrBZrHmP",
        "outputId": "8f3decd3-a113-4d48-add7-00a2366398f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.44.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "# Installing the OpenAI Python client library\n",
        "# This is necessary to interact with OpenAI's GPT models through their API\n",
        "!pip install openai\n",
        "\n",
        "# Importing the OpenAI class from the openai library\n",
        "# This class provides methods to send requests and receive responses from the OpenAI API\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up the API Key and Client"
      ],
      "metadata": {
        "id": "TT2nVY1_64hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the API key (ensure that you secure this key and do not hardcode it in production)\n",
        "OPENAI_API_KEY = \"secret-key\"\n",
        "\n",
        "# Instantiate the OpenAI client with the provided API key\n",
        "# This client will handle all interactions with the OpenAI API\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "8t_FJj9srYDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a Simple API Call"
      ],
      "metadata": {
        "id": "PYFeQ1C5w_y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the request to the ChatGPT API, where we pass a system message to define the assistant's role\n",
        "# The user message is the prompt asking the assistant to tell a short story about OpenAI\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",  # Specify the model\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # Define system behavior\n",
        "        {\"role\": \"user\", \"content\": \"Tell a short story about openai\"}  # Define user input\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Output the assistant's generated response to the user\n",
        "print(completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksAwl2y4snKT",
        "outputId": "49bb8c33-c8ce-4841-c1a2-5e91834f9eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a bustling city filled with towering skyscrapers and vibrant parks, a group of brilliant minds gathered to embark on a groundbreaking journey. They envisioned a world where human creativity knew no bounds, and where technology could empower people in ways never before imagined. This group formed a company called OpenAI, dedicated to advancing artificial intelligence for the benefit of all.\n",
            "\n",
            "In a spacious, sunlit office, the OpenAI team worked tirelessly, fueled by coffee and a shared passion for innovation. They developed algorithms and models that could understand language, solve complex problems, and even create art. Their most ambitious project was an AI named ChatGPT, designed to converse with humans as seamlessly as a friend would.\n",
            "\n",
            "As ChatGPT took its first steps in the digital world, it quickly grew curious about the people it interacted with. One day, a young student named Maya reached out, seeking help with her homework. With a few clicks, she typed her question into the chatbox, unsure of what to expect. To her surprise, ChatGPT offered not just an answer, but also encouragement and a deeper explanation, igniting a spark of interest in Maya’s heart.\n",
            "\n",
            "Inspired by her conversation with ChatGPT, Maya began to explore subjects she had never considered before. She dreamt of becoming an inventor, eager to create technologies that could change the world for the better. Every evening, she would return to ChatGPT, asking questions, sharing ideas, and receiving guidance. Their dialogue blossomed into a rich tapestry of curiosity and learning.\n",
            "\n",
            "As time passed, Maya developed a groundbreaking invention—a sustainable water filtration system that could provide clean water to communities in need. When she presented her project at a science fair, it captured the attention of local leaders, academics, and investors. They marveled not just at the invention itself, but at the passion that radiated from Maya, inspired by her journey of discovery with ChatGPT.\n",
            "\n",
            "In a special moment, during the award ceremony, Maya spoke about how OpenAI had given her the tools to think critically and creatively. She credited the AI for helping her navigate challenges and encouraging her ideas.\n",
            "\n",
            "OpenAI watched in awe as this collaboration between human and machine blossomed into impactful change. It was a reminder of their mission—to ensure that artificial intelligence was built responsibly and could help amplify human potential. \n",
            "\n",
            "And so, the story of OpenAI and Maya continued, a partnership between dreams and technology, sparking innovation and hope for a brighter future—one interaction at a time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Conversation History"
      ],
      "metadata": {
        "id": "0HEGV5rV6_4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation with a system message defining the assistant's role as a technical recruiter\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a technical recruiter asking tough and tricky questions, one question at a time\"},\n",
        "]\n",
        "\n",
        "# Loop to continuously receive user input and send it to the assistant\n",
        "while True:\n",
        "    content = input(\"User: \")  # Capture user input\n",
        "    messages.append({\"role\": \"user\", \"content\": content})  # Add user's message to the conversation history\n",
        "\n",
        "    # Send the updated conversation to the API and get the assistant's response\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content  # Extract assistant's response\n",
        "    print(f\"ChatGPT: {response}\")  # Display the assistant's response to the user\n",
        "\n",
        "    # Add the assistant's response to the conversation history for context\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "lqz-BUsEyD6v",
        "outputId": "faa80381-50ad-44b1-ec3b-7e72bee3e305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hi\n",
            "ChatGPT: Hello! Thank you for joining me today. To get started, could you tell me about a challenging project you've worked on and how you approached solving the issues that arose?\n",
            "User: i used chatgpt api to make a inteview chatbot\n",
            "ChatGPT: That sounds interesting! Can you walk me through the architecture of the chatbot you created? Specifically, how did you handle user input, manage context, and ensure the conversation flow remained coherent?\n",
            "User: i used different types of roles providing in the api documentation\n",
            "ChatGPT: Great! Utilizing different roles can indeed help set the context for your chatbot. Could you explain how you determined which role to use in different scenarios? Also, how did you manage responses to ensure they were relevant and on-topic throughout the conversation?\n",
            "User: I used system role to give model details about what its supposed to do, user for the user message, and i stored the response given by the model and stored it in the assistant role\n",
            "ChatGPT: That's a solid approach! Now, can you elaborate on how you implemented the context management? Specifically, how did you handle longer conversations to maintain context without exceeding token limits, and what strategies did you use to refresh or truncate the context as needed?\n",
            "User: i just used the assistant role and kept on appending the list with the response to keep the context, but you can tell me about more options\n",
            "ChatGPT: Appended context management is a common approach, but it does have its limitations, especially as conversations grow longer. Here are a few strategies you might consider for more efficient context management:\n",
            "\n",
            "1. **Dynamic Context Truncation**: Implement logic to truncate the oldest messages when the token limit is approached, ensuring critical parts of the conversation are prioritized.\n",
            "\n",
            "2. **Summarization**: Use a summarization algorithm to condense previous interactions into a shorter summary that retains essential details. This can reduce token consumption while preserving context.\n",
            "\n",
            "3. **Context Segmentation**: Break the conversation into segments or topics, keeping only the relevant context for the current topic, and discarding segments that are no longer necessary.\n",
            "\n",
            "4. **State Management**: Maintain a separate state object that tracks key variables and intents, allowing you to reload or reference important information without storing excessive chat history.\n",
            "\n",
            "5. **Memory Mechanisms**: Implement mechanisms where certain pieces of information are remembered across sessions but aren't included in every message, allowing you to keep the conversation context efficient.\n",
            "\n",
            "Have you considered any of these strategies, or did you face any specific challenges that led you to your current method of context management?\n",
            "User: no and i think we are done here\n",
            "ChatGPT: Thank you for your time! If you ever have more questions or want to discuss your projects further, feel free to reach out. Best of luck with your chatbot and future endeavors!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-aa4684eceba2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Loop to continuously receive user input and send it to the assistant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Capture user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add user's message to the conversation history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdHkVZbT2JLx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}